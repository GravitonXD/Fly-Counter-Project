{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FISH FRY COUNTER PREPROCESSING\n",
    "Developed by: John Markton M. Olarte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\ACD\\2nd Semester\\CMSC174\\Fly-Counter-Project\\old_files\\fry_counter_preprocesing.ipynb Cell 4\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/ACD/2nd%20Semester/CMSC174/Fly-Counter-Project/old_files/fry_counter_preprocesing.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sample_img \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39m./IMAGES/100/my_photo-1.jpg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/ACD/2nd%20Semester/CMSC174/Fly-Counter-Project/old_files/fry_counter_preprocesing.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sample_img \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39;49mcvtColor(sample_img, cv\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/ACD/2nd%20Semester/CMSC174/Fly-Counter-Project/old_files/fry_counter_preprocesing.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(sample_img, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "sample_img = cv.imread('../IMAGES/100/my_photo-1.jpg')\n",
    "sample_img = cv.cvtColor(sample_img, cv.COLOR_BGR2GRAY)\n",
    "plt.imshow(sample_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img):\n",
    "    img_centerX = img.shape[1] // 2\n",
    "    img_centerY = img.shape[0] // 2\n",
    "\n",
    "    # Initialize mask to use\n",
    "    mask = np.zeros(img.shape, dtype=np.uint8)\n",
    "\n",
    "    # Crop the image\n",
    "    region_to_cut = cv.ellipse(mask, (img_centerX, img_centerY), (547, 547), 0, 0, 360, 255, -1)\n",
    "    cropped_img = cv.bitwise_or(img, img, mask=region_to_cut)\n",
    "    return cropped_img[:, img_centerX-600:img_centerX+600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_img(img):\n",
    "    return cv.bitwise_not(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Crop the image to exclude the reflection of the fry in the side walls of the bin\n",
    "    Invert the image to help reduce the impact of salt-and-pepper noise, without using any blurring methods\n",
    "\n",
    "    Gaussian blur was not utilized since it excludes the thin fry from being detected.\n",
    "\"\"\"\n",
    "sample_img_cropped = crop_img(sample_img)\n",
    "sample_img_inv = invert_img(sample_img_cropped)\n",
    "plt.imshow(sample_img_inv, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the background image\n",
    "bg_img = cv.imread('../IMAGES/100/background.jpg')\n",
    "bg_img = cv.cvtColor(bg_img, cv.COLOR_BGR2GRAY)\n",
    "bg_img_cropped = crop_img(bg_img)\n",
    "bg_img_inv = invert_img(bg_img_cropped)\n",
    "plt.imshow(bg_img_inv, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the background image data\n",
    "diff_img = cv.absdiff(sample_img_inv, bg_img_inv)\n",
    "plt.imshow(diff_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Threshold using adaptive gaussian threshold method, this was used since there are different \n",
    "        brightness level of the fry based on their depth in the container.\n",
    "\"\"\"\n",
    "thresh = cv.adaptiveThreshold(invert_img(diff_img), 256, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 31,5)\n",
    "plt.imshow(thresh, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_black_pixels(thresh):\n",
    "    return np.count_nonzero(thresh == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the  black pixels\n",
    "print(count_black_pixels(thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contours\n",
    "contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "img = cv.drawContours(sample_img_cropped, contours, -1, (0, 255, 0), 1)\n",
    "plt.imshow(img, cmap='gray')\n",
    "print(len(contours))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe for training (100, 200, 300, and 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the images (100)\n",
    "path = '../IMAGES/100/'\n",
    "list_images_100 = [f for f in os.listdir(path) if f.startswith('my_photo')]\n",
    "list_paths_100 = [path + f for f in list_images_100]\n",
    "\n",
    "# Path to the images (200)\n",
    "path = '../IMAGES/200/'\n",
    "list_images_200 = [f for f in os.listdir(path) if f.startswith('my_photo')]\n",
    "list_paths_200 = [path + f for f in list_images_200]\n",
    "\n",
    "# Path to the images (300)\n",
    "path = '../IMAGES/300/'\n",
    "list_images_300 = [f for f in os.listdir(path) if f.startswith('my_photo')]\n",
    "list_paths_300 = [path + f for f in list_images_300]\n",
    "\n",
    "# Path to the images (400)\n",
    "path = '../IMAGES/400/'\n",
    "list_images_400 = [f for f in os.listdir(path) if f.startswith('my_photo')]\n",
    "list_paths_400 = [path + f for f in list_images_400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['black_pixels', 'contours', 'label'])\n",
    "os.makedirs('./exported_df', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image with 100\n",
    "df_100 = df.copy()\n",
    "for img_path in list_paths_100:\n",
    "    img = cv.imread(img_path)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img_cropped = crop_img(img)\n",
    "    img_inv = invert_img(img_cropped)\n",
    "    diff_img = cv.absdiff(img_inv, bg_img_inv)\n",
    "    thresh = cv.adaptiveThreshold(invert_img(diff_img), 256, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 31,5)\n",
    "    black_pixels = count_black_pixels(thresh)\n",
    "    contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    df_100 = pd.concat([df_100, pd.DataFrame({'black_pixels': [black_pixels], 'contours': [len(contours)], 'label': [100]})], ignore_index=True)\n",
    "\n",
    "df_100.to_csv('./exported_df/df_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image with 200\n",
    "df_200 = df.copy()\n",
    "for img_path in list_paths_200:\n",
    "    img = cv.imread(img_path)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img_cropped = crop_img(img)\n",
    "    img_inv = invert_img(img_cropped)\n",
    "    diff_img = cv.absdiff(img_inv, bg_img_inv)\n",
    "    thresh = cv.adaptiveThreshold(invert_img(diff_img), 256, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 31,5)\n",
    "    black_pixels = count_black_pixels(thresh)\n",
    "    contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    df_200 = pd.concat([df_200, pd.DataFrame({'black_pixels': [black_pixels], 'contours': [len(contours)], 'label': [200]})], ignore_index=True)\n",
    "\n",
    "df_200.to_csv('./exported_df/df_200.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image with 300\n",
    "df_300 = df.copy()\n",
    "for img_path in list_paths_300:\n",
    "    img = cv.imread(img_path)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img_cropped = crop_img(img)\n",
    "    img_inv = invert_img(img_cropped)\n",
    "    diff_img = cv.absdiff(img_inv, bg_img_inv)\n",
    "    thresh = cv.adaptiveThreshold(invert_img(diff_img), 256, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 31,5)\n",
    "    black_pixels = count_black_pixels(thresh)\n",
    "    contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    df_300 = pd.concat([df_300, pd.DataFrame({'black_pixels': [black_pixels], 'contours': [len(contours)], 'label': [300]})], ignore_index=True)\n",
    "\n",
    "df_300.to_csv('./exported_df/df_300.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image with 400\n",
    "df_400 = df.copy()\n",
    "for img_path in list_paths_400:\n",
    "    img = cv.imread(img_path)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img_cropped = crop_img(img)\n",
    "    img_inv = invert_img(img_cropped)\n",
    "    diff_img = cv.absdiff(img_inv, bg_img_inv)\n",
    "    thresh = cv.adaptiveThreshold(invert_img(diff_img), 256, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 31,5)\n",
    "    black_pixels = count_black_pixels(thresh)\n",
    "    contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    df_400 = pd.concat([df_400, pd.DataFrame({'black_pixels': [black_pixels], 'contours': [len(contours)], 'label': [400]})], ignore_index=True)\n",
    "\n",
    "df_400.to_csv('./exported_df/df_400.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum black_pixels: ', df_100['black_pixels'].min(), df_200['black_pixels'].min(), df_300['black_pixels'].min(), df_400['black_pixels'].min())\n",
    "print('Maximum black_pixels: ', df_100['black_pixels'].max(), df_200['black_pixels'].max(), df_300['black_pixels'].max(), df_400['black_pixels'].max())\n",
    "print('Minimum contours: ', df_100['contours'].min(), df_200['contours'].min(), df_300['contours'].min(), df_400['contours'].min())\n",
    "print('Maximum contours: ', df_100['contours'].max(), df_200['contours'].max(), df_300['contours'].max(), df_400['contours'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot for the minimum and maximum white_pixels and contours for each label\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(df_100['white_pixels'], df_100['contours'], label='100')\n",
    "plt.scatter(df_200['white_pixels'], df_200['contours'], label='200')\n",
    "plt.scatter(df_300['white_pixels'], df_300['contours'], label='300')\n",
    "plt.scatter(df_400['white_pixels'], df_400['contours'], label='400')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
