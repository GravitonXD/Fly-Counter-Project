{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the images (100)\n",
    "path = './IMAGES/100/'\n",
    "list_images_100 = [f for f in os.listdir(path) if f.startswith('my_photo')]\n",
    "list_paths_100 = [path + f for f in list_images_100]\n",
    "\n",
    "# Path to the images (200)\n",
    "path = './IMAGES/200/'\n",
    "list_images_200 = [f for f in os.listdir(path) if f.startswith('my_photo')]\n",
    "list_paths_200 = [path + f for f in list_images_200]\n",
    "\n",
    "# Path to the images (300)\n",
    "path = './IMAGES/300/'\n",
    "list_images_300 = [f for f in os.listdir(path) if f.startswith('my_photo')]\n",
    "list_paths_300 = [path + f for f in list_images_300]\n",
    "\n",
    "# Path to the images (400)\n",
    "path = './IMAGES/400/'\n",
    "list_images_400 = [f for f in os.listdir(path) if f.startswith('my_photo')]\n",
    "list_paths_400 = [path + f for f in list_images_400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img):\n",
    "    img_centerX = img.shape[1] // 2\n",
    "    img_centerY = img.shape[0] // 2\n",
    "    mask = np.zeros(img.shape, dtype=np.uint8)\n",
    "    region_to_cut = cv.ellipse(mask, (img_centerX, img_centerY), (547, 547), 0, 0, 360, 255, -1)\n",
    "    cropped_img = cv.bitwise_or(img, img, mask=region_to_cut)\n",
    "    return cropped_img[:, img_centerX-600:img_centerX+600]\n",
    "\n",
    "def invert_img(img):\n",
    "    return cv.bitwise_not(img)\n",
    "\n",
    "def count_black_pixels(thresh):\n",
    "    return np.count_nonzero(thresh == 0)\n",
    "\n",
    "def init_bg(c=100):\n",
    "    bg_img = cv.imread(f'./IMAGES/{c}/background.jpg')\n",
    "    bg_img = cv.cvtColor(bg_img, cv.COLOR_BGR2GRAY)\n",
    "    bg_img_cropped = crop_img(bg_img)\n",
    "    return invert_img(bg_img_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(img, bg_img):\n",
    "    # Process Image\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img_cropped = crop_img(img_gray)\n",
    "    img_inv = invert_img(img_cropped)\n",
    "\n",
    "    # Difference and Threshold\n",
    "    diff_img = cv.absdiff(img_inv, bg_img)\n",
    "    thresh = cv.adaptiveThreshold(invert_img(diff_img), 256, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 31,5)\n",
    "\n",
    "    # Black pixel count\n",
    "    black_pixel_count = count_black_pixels(thresh)\n",
    "    # Contours\n",
    "    contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    \"\"\"\n",
    "        FRY COUNT\n",
    "        100, if black_pixel_count is between 19963 and 21307 and contour length is between 176 to 228\n",
    "        200, if black_pixel_count is between 62611 and 67718 and contour length is between 1243 to 1436\n",
    "        300, if black_pixel_count is between 77774 and 87826 and contour length is between 1238 to 1580\n",
    "        400, if black_pixel_count is between 102196 and 110531 and contour length is between 1409 to 1590\n",
    "    \"\"\"\n",
    "    if 19963 <= black_pixel_count <= 21307 and 176 <= len(contours) <= 228:\n",
    "        return 100, img\n",
    "    elif 62611 <= black_pixel_count <= 67718 and 1243 <= len(contours) <= 1436:\n",
    "        return 200, img\n",
    "    elif 77774 <= black_pixel_count <= 87826 and 1238 <= len(contours) <= 1580:\n",
    "        return 300, img\n",
    "    elif 102196 <= black_pixel_count <= 110531 and 1409 <= len(contours) <= 1590:\n",
    "        return 400, img\n",
    "    else:\n",
    "        return 0, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results (for 100 fry count): 100.0% Correctly Identified\n"
     ]
    }
   ],
   "source": [
    "# Validation for 100\n",
    "bg_img = init_bg()\n",
    "total_correct_count = 0\n",
    "for img_path in list_paths_100:\n",
    "    img = cv.imread(img_path)\n",
    "    count, _ = counter(img,bg_img)\n",
    "    if count == 100:\n",
    "        total_correct_count += 1\n",
    "\n",
    "print(f\"Validation Results (for 100 fry count): {total_correct_count/len(list_paths_100) * 100}% Correctly Identified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results (for 200 fry count): 100.0% Correctly Identified\n"
     ]
    }
   ],
   "source": [
    "# Validation for 200\n",
    "bg_img = init_bg()\n",
    "total_correct_count = 0\n",
    "for img_path in list_paths_200:\n",
    "    img = cv.imread(img_path)\n",
    "    count, _ = counter(img,bg_img)\n",
    "    if count == 200:\n",
    "        total_correct_count += 1\n",
    "\n",
    "print(f\"Validation Results (for 200 fry count): {total_correct_count/len(list_paths_200) * 100}% Correctly Identified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results (for 300 fry count): 100.0% Correctly Identified\n"
     ]
    }
   ],
   "source": [
    "# Validation for 300\n",
    "bg_img = init_bg()\n",
    "total_correct_count = 0\n",
    "for img_path in list_paths_300:\n",
    "    img = cv.imread(img_path)\n",
    "    count, _ = counter(img,bg_img)\n",
    "    if count == 300:\n",
    "        total_correct_count += 1\n",
    "\n",
    "print(f\"Validation Results (for 300 fry count): {total_correct_count/len(list_paths_300) * 100}% Correctly Identified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results (for 400 fry count): 100.0% Correctly Identified\n"
     ]
    }
   ],
   "source": [
    "# Validation for 400\n",
    "bg_img = init_bg()\n",
    "total_correct_count = 0\n",
    "for img_path in list_paths_400:\n",
    "    img = cv.imread(img_path)\n",
    "    count, _ = counter(img,bg_img)\n",
    "    if count == 400:\n",
    "        total_correct_count += 1\n",
    "\n",
    "print(f\"Validation Results (for 400 fry count): {total_correct_count/len(list_paths_400) * 100}% Correctly Identified\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
